{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YG68hFukwklf"
      },
      "outputs": [],
      "source": [
        "!pip install pytorch_lightning --quiet\n",
        "!pip install transformers --quiet\n",
        "!pip install datasets --quiet"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install seqeval==0.0.2 --quiet"
      ],
      "metadata": {
        "id": "Ac4i7XoNRzFk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pytorch_lightning as pl\n",
        "from transformers import AutoTokenizer\n",
        "import random\n",
        "from typing import List\n",
        "import h5py\n",
        "import pytorch_lightning as pl\n",
        "import torch\n",
        "import torchmetrics\n",
        "from pytorch_lightning import LightningDataModule, seed_everything, LightningModule, Trainer\n",
        "from pytorch_lightning.callbacks.finetuning import BaseFinetuning\n",
        "from pytorch_lightning.callbacks import ModelCheckpoint\n",
        "from sklearn.model_selection import train_test_split\n",
        "from torch import nn\n",
        "from torch.optim.lr_scheduler import MultiStepLR\n",
        "from torch.optim.optimizer import Optimizer\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from transformers import AutoConfig, AutoModelForTokenClassification\n",
        "# from seqeval.metrics import f1_score, precision_score, recall_score,accuracy_score\n",
        "import numpy as np\n",
        "import seqeval\n",
        "seed_everything(123, workers=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C4SqTl-5Rucv",
        "outputId": "cd06a6aa-8388-407f-ec4f-c666f8223117"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:lightning_lite.utilities.seed:Global seed set to 123\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "123"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import csv\n",
        "import pandas as pd\n",
        "from collections import defaultdict\n",
        "from sklearn.utils import shuffle\n",
        "import random\n",
        "import nltk\n",
        "nltk.download('punkt')\n",
        "import re\n",
        "from nltk.corpus import stopwords\n",
        "nltk.download('stopwords')\n",
        "from nltk.tokenize import sent_tokenize\n",
        "from nltk.tokenize import word_tokenize"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-FRZJCEiKuIU",
        "outputId": "6e3bce44-1d2e-485e-b5fa-6a95828cebbe"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def entities(entity_file):\n",
        "  abs=[]\n",
        "  chemical=[]\n",
        "  disease=[]\n",
        "  sentence_chem=[]\n",
        "  sentence_dis=[]\n",
        "  label=[]\n",
        "  sentence=[]\n",
        "  with open(entity_file) as txt_f:\n",
        "    reader=csv.reader(txt_f, delimiter=\"\\t\")\n",
        "    for row in reader:\n",
        "      if len(row)==1:\n",
        "        if (\"|a|\" in row[0] ) == True:\n",
        "          abs.append(sent_tokenize((row[0].split(\"|a|\"))[1]))\n",
        "      \n",
        "      if len(row)==6:\n",
        "        if row[-2]=='Chemical':\n",
        "          chemical.append(row[-3])\n",
        "        elif row[-2]=='Disease':\n",
        "          disease.append(row[-3])\n",
        "  labels_to_ids= {\n",
        "    'Oth': 0,\n",
        "    'Chemical': 1,\n",
        "    'Disease': 2\n",
        "  }\n",
        "  for i in abs:\n",
        "    for j in i:\n",
        "      l=re.sub('[^a-zA-Z]',' ',j)\n",
        "      l=l.lower()\n",
        "      l=l.split()\n",
        "      l=[word for word in l if not word in stopwords.words('english')]\n",
        "      sentence.append(l)\n",
        "      l=word_tokenize(j)\n",
        "      labs=[]\n",
        "      for k in l:\n",
        "        if k in chemical:\n",
        "          labs.append('Chemical')\n",
        "        elif k in disease:\n",
        "          labs.append('Disease')\n",
        "        else:\n",
        "          labs.append('Oth')\n",
        "      # label.append(' '.join(labs))\n",
        "      label.append([labels_to_ids[i] for i in labs])\n",
        "\n",
        "  f={\n",
        "     'text':sentence,\n",
        "     'labels':label\n",
        "    }\n",
        "  df=pd.DataFrame(f)\n",
        "  return df"
      ],
      "metadata": {
        "id": "WV4pH7acxBFH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_file='/content/CDR_TrainingSet.PubTator.txt'\n",
        "train_df=entities(train_file)\n",
        "test_file='/content/CDR_TestSet.PubTator.txt'\n",
        "test_df=entities(test_file)\n",
        "valid_file='/content/CDR_DevelopmentSet.PubTator.txt'\n",
        "val_df=entities(valid_file)"
      ],
      "metadata": {
        "id": "WM8nZ5_BxBBz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_df.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "X-PCaPf5KFuF",
        "outputId": "32f53d0e-4867-4653-d123-76d1c12076e5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                                text  \\\n",
              "0  [unanesthetized, spontaneously, hypertensive, ...   \n",
              "1  [hypotensive, effect, mg, kg, alpha, methyldop...   \n",
              "2  [naloxone, alone, affect, either, blood, press...   \n",
              "3  [brain, membranes, spontaneously, hypertensive...   \n",
              "4  [findings, indicate, spontaneously, hypertensi...   \n",
              "\n",
              "                                              labels  \n",
              "0  [0, 0, 0, 0, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
              "1         [0, 2, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0]  \n",
              "2               [1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]  \n",
              "3  [0, 0, 0, 0, 0, 2, 0, 1, 0, 0, 0, 0, 0, 0, 0, ...  \n",
              "4  [0, 0, 0, 0, 0, 0, 2, 0, 0, 0, 0, 0, 0, 0, 0, ...  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-14b0f8f7-5477-415d-bc00-55dc79cd1d50\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>labels</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>[unanesthetized, spontaneously, hypertensive, ...</td>\n",
              "      <td>[0, 0, 0, 0, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>[hypotensive, effect, mg, kg, alpha, methyldop...</td>\n",
              "      <td>[0, 2, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>[naloxone, alone, affect, either, blood, press...</td>\n",
              "      <td>[1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>[brain, membranes, spontaneously, hypertensive...</td>\n",
              "      <td>[0, 0, 0, 0, 0, 2, 0, 1, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>[findings, indicate, spontaneously, hypertensi...</td>\n",
              "      <td>[0, 0, 0, 0, 0, 0, 2, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-14b0f8f7-5477-415d-bc00-55dc79cd1d50')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-14b0f8f7-5477-415d-bc00-55dc79cd1d50 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-14b0f8f7-5477-415d-bc00-55dc79cd1d50');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_df.to_csv('cdr_train.csv',index=False)"
      ],
      "metadata": {
        "id": "TMlY0CvWxA7v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_df.to_csv('cdr_test.csv',index=False)"
      ],
      "metadata": {
        "id": "MNlsDA1UxA40"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "val_df.to_csv('cdr_val.csv',index=False)"
      ],
      "metadata": {
        "id": "oHnbF9EJxA1Z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "6I6yoL-jYCWG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def chemprot(abs,ent):\n",
        "  \n",
        "  with open(abs) as ab:\n",
        "    abstract=csv.reader(ab, delimiter=\"\\t\")\n",
        "    pmid_ab=[]\n",
        "    abs=[]\n",
        "    for i in abstract:\n",
        "      pmid_ab.append(i[0])\n",
        "      abs.append(i[1:])\n",
        "  \n",
        "  with open(ent) as et:\n",
        "    entities=csv.reader(et,delimiter='\\t')\n",
        "    pmid_en=[]\n",
        "    ner=[]\n",
        "    name=[]\n",
        "    gene=[]\n",
        "    chemical=[]\n",
        "    for j in entities:\n",
        "      if j[2]=='CHEMICAL':\n",
        "        chemical.append(j[5])\n",
        "      else:\n",
        "        gene.append(j[5])\n",
        "  \n",
        "  text=[]\n",
        "  labels=[]\n",
        "  labels_to_ids= {\n",
        "    'Oth': 0,\n",
        "    'Chemical': 1,\n",
        "    'Gene': 3\n",
        "  }\n",
        "  for i in range(len(abs)):\n",
        "    for j in range(len(abs[i])):\n",
        "      l1=sent_tokenize(abs[i][j])\n",
        "      for y in l1:\n",
        "        l=re.sub('[^a-zA-Z]',' ',y)\n",
        "        l=l.lower()\n",
        "        l=l.split()\n",
        "        l=[word for word in l if not word in stopwords.words('english')]\n",
        "        l3=[]\n",
        "        for m in range(len(l)):   \n",
        "            if l[m] in chemical:\n",
        "              l3.append('Chemical')\n",
        "            elif l[m] in gene:\n",
        "              l3.append('Gene')\n",
        "            else:\n",
        "              l3.append('Oth')\n",
        "        if ('Chemical' or 'Gene') in l3:\n",
        "          text.append(l)\n",
        "          # labels.append(l3)\n",
        "          labels.append([labels_to_ids[i] for i in l3]) \n",
        "  f={\n",
        "     'text':text,\n",
        "     'labels':labels\n",
        "    }\n",
        "  df=pd.DataFrame(f)\n",
        "  return df  \n"
      ],
      "metadata": {
        "id": "oxPnwms-xAvS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tr_abs='/content/chemprot_training_abstracts.tsv'\n",
        "tr_ent='/content/chemprot_training_entities.tsv'\n",
        "train=chemprot(tr_abs,tr_ent)\n"
      ],
      "metadata": {
        "id": "iHpWgWRrKyNR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_df.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "TwJJjHJpMU0a",
        "outputId": "5f3a946e-6c9a-49ad-b268-96bd0ec1b96f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                                text  \\\n",
              "0  [unanesthetized, spontaneously, hypertensive, ...   \n",
              "1  [hypotensive, effect, mg, kg, alpha, methyldop...   \n",
              "2  [naloxone, alone, affect, either, blood, press...   \n",
              "3  [brain, membranes, spontaneously, hypertensive...   \n",
              "4  [findings, indicate, spontaneously, hypertensi...   \n",
              "\n",
              "                                              labels  \n",
              "0  [0, 0, 0, 0, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
              "1         [0, 2, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0]  \n",
              "2               [1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]  \n",
              "3  [0, 0, 0, 0, 0, 2, 0, 1, 0, 0, 0, 0, 0, 0, 0, ...  \n",
              "4  [0, 0, 0, 0, 0, 0, 2, 0, 0, 0, 0, 0, 0, 0, 0, ...  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-2f7ee9d8-6078-464f-a13d-9b028db38d7d\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>labels</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>[unanesthetized, spontaneously, hypertensive, ...</td>\n",
              "      <td>[0, 0, 0, 0, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>[hypotensive, effect, mg, kg, alpha, methyldop...</td>\n",
              "      <td>[0, 2, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>[naloxone, alone, affect, either, blood, press...</td>\n",
              "      <td>[1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>[brain, membranes, spontaneously, hypertensive...</td>\n",
              "      <td>[0, 0, 0, 0, 0, 2, 0, 1, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>[findings, indicate, spontaneously, hypertensi...</td>\n",
              "      <td>[0, 0, 0, 0, 0, 0, 2, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-2f7ee9d8-6078-464f-a13d-9b028db38d7d')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-2f7ee9d8-6078-464f-a13d-9b028db38d7d button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-2f7ee9d8-6078-464f-a13d-9b028db38d7d');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train.to_csv('chemprot_train.csv',index=False)"
      ],
      "metadata": {
        "id": "FAFqqxnrMZof"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "te_abs='/content/chemprot_test_abstracts_gs.tsv'\n",
        "te_ent='/content/chemprot_test_entities_gs.tsv'\n",
        "test=chemprot(te_abs,te_ent)\n"
      ],
      "metadata": {
        "id": "fyq1g_WUYDOY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test.to_csv('chemprot_test.csv',index=False)"
      ],
      "metadata": {
        "id": "JFu8guz-MaPE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "de_abs='/content/chemprot_development_abstracts.tsv'\n",
        "de_ent='/content/chemprot_development_entities.tsv'\n",
        "val=chemprot(de_abs,de_ent)"
      ],
      "metadata": {
        "id": "3ohCRpHKMTnZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "val.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "_w-50L3yNuUw",
        "outputId": "3db53078-b192-499e-d734-ece2b466d30e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                                text  \\\n",
              "0  [binding, dimemorfan, sigma, receptor, anticon...   \n",
              "1  [dextromethorphan, methoxy, n, methylmorphinan...   \n",
              "2  [mechanisms, cns, effects, dm, suggested, asso...   \n",
              "3  [dm, largely, demethylated, phencyclidine, pcp...   \n",
              "4  [dimemorfan, methyl, n, methylmorphinan, df, a...   \n",
              "\n",
              "                                              labels  \n",
              "0                  [0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1]  \n",
              "1                        [1, 1, 0, 0, 0, 0, 0, 0, 0]  \n",
              "2  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, ...  \n",
              "3  [0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, ...  \n",
              "4      [1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-bd9540de-dc30-411e-9d7e-a815429a5846\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>labels</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>[binding, dimemorfan, sigma, receptor, anticon...</td>\n",
              "      <td>[0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>[dextromethorphan, methoxy, n, methylmorphinan...</td>\n",
              "      <td>[1, 1, 0, 0, 0, 0, 0, 0, 0]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>[mechanisms, cns, effects, dm, suggested, asso...</td>\n",
              "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>[dm, largely, demethylated, phencyclidine, pcp...</td>\n",
              "      <td>[0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>[dimemorfan, methyl, n, methylmorphinan, df, a...</td>\n",
              "      <td>[1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-bd9540de-dc30-411e-9d7e-a815429a5846')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-bd9540de-dc30-411e-9d7e-a815429a5846 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-bd9540de-dc30-411e-9d7e-a815429a5846');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 47
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "val.to_csv('chemprot_val.csv',index=False)"
      ],
      "metadata": {
        "id": "jy_VrcLMMa_O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train1 = train_df.append(train, ignore_index=True)"
      ],
      "metadata": {
        "id": "YOwNyAD6mYl2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train1.to_csv('train.csv',index=False)"
      ],
      "metadata": {
        "id": "MTQY5Jmn1bcQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train1.columns"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8JEl4z0A0e23",
        "outputId": "6abbadcd-d5c3-4a0f-c888-c41b353a95de"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Index(['text', 'labels'], dtype='object')"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train1.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UAmALjoAmiTq",
        "outputId": "d3cb78fd-c3e2-4b9a-c145-9c3ebc43b927"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(9167, 2)"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "val1=val_df.append(val,ignore_index=True)"
      ],
      "metadata": {
        "id": "Qvb6JqZ_WFMR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "val1.to_csv('val.csv',index=False)"
      ],
      "metadata": {
        "id": "eOlta85u1nLN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "val1.columns"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BRuRCQrwW3dY",
        "outputId": "34016813-de95-41ab-cd1b-13fd524a40e7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Index(['text', 'labels'], dtype='object')"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test1=test_df.append(test,ignore_index=True)"
      ],
      "metadata": {
        "id": "iTawdyh4g0_C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test1.to_csv('test.csv',index=False)"
      ],
      "metadata": {
        "id": "3Ynzzo24zNon"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test1.columns"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g2dIrLEo1_-z",
        "outputId": "78264b74-c8ea-4720-ff4b-d6341f3421d6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Index(['text', 'labels'], dtype='object')"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train1=train_df[:100]\n",
        "test1=test_df[:100]\n",
        "val1=val_df[:100]"
      ],
      "metadata": {
        "id": "Nc2aRL_xfdtb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoTokenizer, AutoModel\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"dmis-lab/biobert-v1.1\")\n",
        "\n",
        "model = AutoModel.from_pretrained(\"dmis-lab/biobert-v1.1\",num_labels=4)"
      ],
      "metadata": {
        "id": "IJRY-5bjxAW0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "label_names=[0,1,2,3]"
      ],
      "metadata": {
        "id": "aCtENCw_U8M5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "input=tokenizer(train1['text'][0],is_split_into_words=True,max_length=128, truncation=True,padding=\"max_length\")"
      ],
      "metadata": {
        "id": "q-3Ee4blU8Hk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "input.tokens()"
      ],
      "metadata": {
        "id": "mgKTHy4MU8EJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "input.word_ids"
      ],
      "metadata": {
        "id": "yZBsaIZ3U8AP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "62dc34f3-ba38-4ed2-bfaa-2c44820d718f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<bound method BatchEncoding.word_ids of {'input_ids': [101, 8362, 6354, 2050, 4638, 26300, 20061, 1193, 177, 24312, 27291, 13475, 9711, 1892, 2997, 1762, 2603, 1666, 1107, 4487, 7912, 2285, 172, 4934, 2386, 2042, 17599, 12139, 1116, 4023, 1107, 23034, 1174, 11802, 9468, 2858, 19315, 17713, 4023, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'token_type_ids': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]}>"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "oLC7inIoeRMH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def align_labels_with_tokens(labels, word_ids):\n",
        "  \n",
        "    new_labels = []\n",
        "    current_word = None\n",
        "    for word_id in word_ids:\n",
        "        if word_id != current_word:\n",
        "            # Start of a new word!\n",
        "            current_word = word_id\n",
        "            label = 0 if word_id is None else labels[word_id]\n",
        "            new_labels.append(label)\n",
        "        elif word_id is None:\n",
        "            # Special token\n",
        "            new_labels.append(0)\n",
        "        else:\n",
        "            # Same word as previous token\n",
        "            label = labels[word_id]\n",
        "            new_labels.append(label)\n",
        "\n",
        "    return new_labels"
      ],
      "metadata": {
        "id": "bwq2aWhuU78z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "labels = train_df['labels'][0]\n",
        "word_ids = input.word_ids()\n",
        "print(labels)\n",
        "print(len(align_labels_with_tokens(labels, word_ids)))"
      ],
      "metadata": {
        "id": "-LsC2ApQWEX-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "17010719-d40f-4d0c-bc01-9a5f1efb1948"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0, 0, 0, 0, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0]\n",
            "128\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def tokenize_and_align_labels(df):\n",
        "  label_ids=[]\n",
        "  input_ids=[]\n",
        "  attention_mask=[]\n",
        "  token_type_ids=[]\n",
        "\n",
        "  for i in range(len(df['text'])):\n",
        "      tokenized_inputs = tokenizer(\n",
        "          df['text'][i], truncation=True, is_split_into_words=True,max_length=256,padding=\"max_length\"\n",
        "      )\n",
        "      input_ids.append(tokenized_inputs['input_ids'])\n",
        "      attention_mask.append(tokenized_inputs['attention_mask'])\n",
        "      token_type_ids.append(tokenized_inputs['token_type_ids'])\n",
        "      all_labels = df['labels'][i]\n",
        "     \n",
        "      word_ids = tokenized_inputs.word_ids()\n",
        "      label_ids.append(align_labels_with_tokens(all_labels, word_ids))\n",
        "\n",
        "      return input_ids,attention_mask,token_type_ids,label_ids"
      ],
      "metadata": {
        "id": "FhgAMSP0WEUw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df=train_df[:1]"
      ],
      "metadata": {
        "id": "AmgVuZjhWERn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "d=tokenize_and_align_labels(df)\n",
        "# d[2]"
      ],
      "metadata": {
        "id": "OwkUnB3EWEOX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class dataset(Dataset):\n",
        "    def __init__(self, dataframe, tokenizer, max_len):\n",
        "        self.len = len(dataframe)\n",
        "        self.data = dataframe\n",
        "        self.tokenizer = tokenizer\n",
        "        self.max_len = max_len\n",
        "        \n",
        "    def __getitem__(self, index):\n",
        "        # step 1: tokenize (and adapt corresponding labels)\n",
        "        sentence = self.data.text[index]  \n",
        "        word_labels = self.data.labels[index]  \n",
        "        tokenized_inputs = self.tokenizer(\n",
        "          sentence, truncation=True, is_split_into_words=True,max_length=self.max_len,padding=\"max_length\")\n",
        "        word_ids = tokenized_inputs.word_ids()\n",
        "        label_ids=align_labels_with_tokens(word_labels, word_ids)\n",
        "        input_ids=(tokenized_inputs['input_ids'])\n",
        "        attention_mask=(tokenized_inputs['attention_mask'])\n",
        "        token_type_ids=(tokenized_inputs['token_type_ids'])\n",
        "        return input_ids, attention_mask,token_type_ids, label_ids\n",
        "    \n",
        "    def __len__(self):\n",
        "        return self.len"
      ],
      "metadata": {
        "id": "FrTJfgrZWELQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def my_collate(batch):\n",
        "    input_ids = np.asarray([item[0] for item in batch])\n",
        "    attention_mask = np.asarray([item[1] for item in batch])\n",
        "    token_type_ids = np.asarray([item[2] for item in batch])\n",
        "    label_ids = np.asarray([item[3] for item in batch])\n",
        "    return torch.LongTensor(input_ids), torch.LongTensor(attention_mask),torch.LongTensor(token_type_ids),torch.LongTensor(label_ids)\n",
        "\n",
        "class TransformerDataModule(LightningDataModule):\n",
        "    def __init__(self,train_df,val_df,test_df, tokenizer,max_len=128,batch_size: int = 16):\n",
        "        super().__init__()\n",
        "        self.val_df=val_df\n",
        "        self.test_df=test_df\n",
        "        self.train_df=train_df\n",
        "        self.batch_size = batch_size\n",
        "        self.valid_dataset = None\n",
        "        self.train_dataset = None\n",
        "        self.test_dataset=None\n",
        "        self.tokenizer=tokenizer\n",
        "        self.max_len=max_len\n",
        "\n",
        "    def prepare_data(self, *args, **kwargs):\n",
        "        pass\n",
        "\n",
        "    def setup(self, **kwargs):\n",
        "        \"\"\"define train and validation datasets \"\"\"\n",
        "        self.train_dataset = dataset(self.train_df,self.tokenizer,self.max_len)\n",
        "        self.valid_dataset = dataset(self.val_df,self.tokenizer,self.max_len)\n",
        "        self.test_dataset = dataset(self.test_df,self.tokenizer,self.max_len)\n",
        "\n",
        "    def train_dataloader(self):\n",
        "        \"\"\"returns train dataloader\"\"\"\n",
        "        loader = DataLoader(self.train_dataset, batch_size=self.batch_size, shuffle=True,\n",
        "                            num_workers=2, pin_memory=True, collate_fn = my_collate)\n",
        "        return loader\n",
        "    \n",
        "    def val_dataloader(self):\n",
        "        \"\"\"returns val dataloader\"\"\"\n",
        "        loader = DataLoader(self.valid_dataset, batch_size=self.batch_size, shuffle=False,\n",
        "                            num_workers=2, pin_memory=True, collate_fn = my_collate)\n",
        "        return loader\n",
        "\n",
        "    def test_dataloader(self):\n",
        "        loader = DataLoader(self.test_dataset, batch_size=self.batch_size, shuffle=False,\n",
        "                            num_workers=2, pin_memory=True, collate_fn = my_collate)\n",
        "        return loader\n",
        "\n"
      ],
      "metadata": {
        "id": "w8WtuPzJWEIY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data_module = TransformerDataModule(\n",
        "  train1,\n",
        "  val1,\n",
        "  test1,\n",
        "  tokenizer,\n",
        "  batch_size=8\n",
        ")"
      ],
      "metadata": {
        "id": "eTHomexiWEES"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import MultiLabelBinarizer\n",
        "from sklearn.metrics import f1_score\n",
        "import statistics\n",
        "from statistics import mean"
      ],
      "metadata": {
        "id": "KtoUpEfWih7t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "class MilestonesFinetuning(BaseFinetuning):\n",
        "    def __init__(self, milestones: List = [50], train_bn: bool = False):\n",
        "        super().__init__()\n",
        "        self.milestones = milestones\n",
        "        self.train_bn = train_bn\n",
        "\n",
        "    def freeze_before_training(self, pl_module: pl.LightningModule):\n",
        "        self.freeze(modules=pl_module.transformer.bert, train_bn=self.train_bn)\n",
        "\n",
        "    def finetune_function(self, pl_module: pl.LightningModule, epoch: int, optimizer: Optimizer, opt_idx: int):\n",
        "        if epoch == self.milestones[0]:\n",
        "            print('starting model training')\n",
        "            self.unfreeze_and_add_param_group(\n",
        "                modules=pl_module.transformer.bert, optimizer=optimizer, train_bn=self.train_bn\n",
        "            )\n",
        "            \n",
        "class TransformerModel(LightningModule):\n",
        "    \n",
        "    def __init__(self, lr=1e-3, lr_scheduler_gamma=1e-1, milestones=[50]):\n",
        "        super(TransformerModel, self).__init__()\n",
        "\n",
        "        self.lr = lr\n",
        "        self.train_f1_score=[]\n",
        "        self.val_f1_score=[]\n",
        "        self.test_f1_score=[]\n",
        "        self.lr_scheduler_gamma = lr_scheduler_gamma\n",
        "        self.milestones = milestones\n",
        "        self.labels = ['Oth','Chemical','Disease','Gene']\n",
        "        self.label_map={i: label for i, label in enumerate(self.labels)}\n",
        "        self.num_labels = len(self.labels)\n",
        "        self.config = AutoConfig.from_pretrained('dmis-lab/biobert-large-cased-v1.1',\n",
        "                num_labels=self.num_labels,\n",
        "                id2label=self.label_map,\n",
        "                label2id={label: i for i, label in enumerate(self.labels)})\n",
        "        self.transformer = AutoModelForTokenClassification.from_pretrained('dmis-lab/biobert-large-cased-v1.1',config =self.config)\n",
        "        self.save_hyperparameters(\"lr\",\"lr_scheduler_gamma\")\n",
        "        self.binarizer = MultiLabelBinarizer()\n",
        "\n",
        "    def align_predictions(self, predictions: np.ndarray, label_ids: np.ndarray):\n",
        "        preds = predictions.argmax(2)\n",
        "\n",
        "        batch_size, seq_len = preds.shape\n",
        "\n",
        "        out_label_list = [[] for _ in range(batch_size)]\n",
        "        preds_list = [[] for _ in range(batch_size)]\n",
        "        \n",
        "        for i in range(batch_size):\n",
        "            for j in range(seq_len):\n",
        "                if label_ids[i, j] != nn.CrossEntropyLoss().ignore_index:\n",
        "                    out_label_list[i].append(self.label_map[int(label_ids[i][j])])\n",
        "                    preds_list[i].append(self.label_map[int(preds[i][j])])\n",
        "        return out_label_list, preds_list \n",
        "\n",
        "    def forward(self, input_ids, attention_mask, token_type_ids, label_ids):\n",
        "        outputs = self.transformer(input_ids,attention_mask=attention_mask, token_type_ids=token_type_ids,labels = label_ids)\n",
        "        return outputs\n",
        "\n",
        "    def configure_optimizers(self):\n",
        "        parameters = list(self.parameters())\n",
        "        trainable_parameters = list(filter(lambda p: p.requires_grad, parameters))\n",
        "        print(\n",
        "            f\"The model will start training with only {len(trainable_parameters)} \"\n",
        "            f\"trainable parameters out of {len(parameters)}.\"\n",
        "        )\n",
        "        optimizer = torch.optim.AdamW(trainable_parameters, lr=self.lr)\n",
        "        scheduler = MultiStepLR(optimizer, milestones=self.milestones, gamma=self.lr_scheduler_gamma)\n",
        "        return [optimizer], [scheduler]\n",
        "      \n",
        "    def validation_step(self, batch, batch_idx):\n",
        "        input_ids, attention_mask, token_type_ids, label_ids = batch\n",
        "        outputs = self(input_ids, attention_mask, token_type_ids, label_ids)\n",
        "        valid_loss = outputs[0]\n",
        "        logits  = outputs[1]\n",
        "        y_true, y_pred = self.align_predictions(logits,label_ids)\n",
        "        self.binarizer.fit(y_true)\n",
        "        self.val_f1_score.append(f1_score(self.binarizer.transform(y_true), \n",
        "                self.binarizer.transform(y_pred), average='weighted'))\n",
        "        self.log('valid_f1',mean(self.val_f1_score), on_step=False, on_epoch=True, prog_bar=False, logger=True)\n",
        "        # self.log('val_f1',,on_epoch=False, on_step=True, prog_bar=True,\n",
        "        #          logger=True)\n",
        "        # output_labels, predictions = self.align_predictions(logits,label_ids)\n",
        "        # self.binarizer.fit(output_labels)\n",
        "\n",
        "        # self.log('valid_loss', valid_loss, on_step=True, on_epoch=False, prog_bar=False, logger=True)\n",
        "        # self.log('valid_f1',f1_score(self.binarizer.transform(output_labels), \n",
        "        #         self.binarizer.transform(predictions), average='weighted'),on_epoch=False, on_step=True, prog_bar=False,\n",
        "        #          logger=True)\n",
        "        # self.log('valid_precision', precision_score(output_labels, predictions),on_epoch=True, on_step=False, prog_bar=True,\n",
        "        #          logger=True)\n",
        "        # self.log('valid_recall', recall_score(output_labels, predictions),on_epoch=True, on_step=False, prog_bar=True,\n",
        "        #          logger=True)\n",
        "\n",
        "        \n",
        "    def training_step(self, batch, batch_idx):\n",
        "        input_ids, attention_mask, token_type_ids, label_ids = batch\n",
        "        outputs = self(input_ids, attention_mask, token_type_ids, label_ids)\n",
        "        train_loss = outputs[0]\n",
        "        logits  = outputs[1]\n",
        "        y_true, y_pred = self.align_predictions(logits,label_ids)\n",
        "        self.binarizer.fit(y_true)\n",
        "        self.train_f1_score.append(f1_score(self.binarizer.transform(y_true), \n",
        "                self.binarizer.transform(y_pred), average='weighted'))\n",
        "        self.log('train_f1',mean(self.train_f1_score),on_epoch=False, on_step=True, prog_bar=True,\n",
        "                 logger=True)\n",
        "        self.log('train_loss', train_loss, on_step=False, on_epoch=True, prog_bar=False, logger=True)\n",
        "        return train_loss\n",
        "\n",
        "    \n",
        "\n",
        "    def test_step(self, batch, batch_idx):\n",
        "        input_ids, attention_mask, token_type_ids, label_ids = batch\n",
        "        outputs = self(input_ids, attention_mask, token_type_ids, label_ids)\n",
        "        test_loss = outputs[0]\n",
        "        logits  = outputs[1]\n",
        "        output_labels, predictions = self.align_predictions(logits,label_ids)\n",
        "        self.log('test_loss', test_loss, on_step=True, on_epoch=False, prog_bar=False, logger=True)\n",
        "        self.log('test_f1', f1_score(output_labels, predictions),on_epoch=True, on_step=False, prog_bar=True,\n",
        "                 logger=True)\n",
        "        # self.log('test_precision', precision_score(output_labels, predictions),on_epoch=True, on_step=False, prog_bar=True,\n",
        "        #          logger=True)\n",
        "        # self.log('test_recall', recall_score(output_labels, predictions),on_epoch=True, on_step=False, prog_bar=True,\n",
        "        #          logger=True)\n",
        "        \n",
        "        return test_loss"
      ],
      "metadata": {
        "id": "4TBbrwReWEA-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = TransformerModel()"
      ],
      "metadata": {
        "id": "ree3Z3ILWD9D",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a93e215b-43ff-435d-a85a-3495c07acfa0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of the model checkpoint at dmis-lab/biobert-large-cased-v1.1 were not used when initializing BertForTokenClassification: ['cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.bias', 'cls.predictions.decoder.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.weight']\n",
            "- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of BertForTokenClassification were not initialized from the model checkpoint at dmis-lab/biobert-large-cased-v1.1 and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "trainer = Trainer(max_epochs=10, gpus=1,\n",
        "                  callbacks=[ModelCheckpoint(monitor='valid_f1', mode='max'), MilestonesFinetuning()])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tSq2Vc7VXe7e",
        "outputId": "5abf46e0-3019-40a8-b8ae-b002ee013679"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/pytorch_lightning/trainer/connectors/accelerator_connector.py:447: LightningDeprecationWarning: Setting `Trainer(gpus=1)` is deprecated in v1.7 and will be removed in v2.0. Please use `Trainer(accelerator='gpu', devices=1)` instead.\n",
            "  f\"Setting `Trainer(gpus={gpus!r})` is deprecated in v1.7 and will be removed\"\n",
            "INFO:pytorch_lightning.utilities.rank_zero:GPU available: True (cuda), used: True\n",
            "INFO:pytorch_lightning.utilities.rank_zero:TPU available: False, using: 0 TPU cores\n",
            "INFO:pytorch_lightning.utilities.rank_zero:IPU available: False, using: 0 IPUs\n",
            "INFO:pytorch_lightning.utilities.rank_zero:HPU available: False, using: 0 HPUs\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "trainer.fit(model,data_module)"
      ],
      "metadata": {
        "id": "sXIzYZZFXe3U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Agw6MpPOcMcz",
        "outputId": "c9533b37-87c0-45ca-b1c6-fbef1e9313f9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer = AutoTokenizer.from_pretrained('dmis-lab/biobert-large-cased-v1.1') \n",
        "model = TransformerModel.load_from_checkpoint('/content/gdrive/MyDrive/epoch=2-step=13752.ckpt')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2QEP4SxIXez3",
        "outputId": "59f7f959-100f-411e-e2ee-721f118b5df1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of the model checkpoint at dmis-lab/biobert-large-cased-v1.1 were not used when initializing BertForTokenClassification: ['cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.bias', 'cls.predictions.decoder.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.weight']\n",
            "- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of BertForTokenClassification were not initialized from the model checkpoint at dmis-lab/biobert-large-cased-v1.1 and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "labels = ['Oth','Chemical','Disease','Gene']\n",
        "label_map={i: label for i, label in enumerate(labels)}"
      ],
      "metadata": {
        "id": "7plYMhaOc8Uc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_predictions(sentence):\n",
        "  tok = tokenizer(sentence, padding = 'max_length', max_length = 128)\n",
        "  tokens = tokenizer.tokenize(sentence)\n",
        "  input_ids, attention_mask, token_type_ids = tok['input_ids'], tok['attention_mask'],tok['token_type_ids']\n",
        "  token_type_ids[0] = 1\n",
        "  output = model(torch.LongTensor(input_ids).unsqueeze(0), torch.LongTensor(attention_mask).unsqueeze(0), torch.LongTensor(token_type_ids).unsqueeze(0), torch.LongTensor([0 for i in range(128)]).unsqueeze(0))[1]\n",
        "  labels_out = output.argmax(2).squeeze(0).numpy().tolist()[1:len(tokens)+1]\n",
        "  entities = [label_map[i] for i in labels_out]\n",
        "  new_tokens, new_labels = [], []\n",
        "  # final_tokens, final_labels = [], []\n",
        "  for token, label_idx in zip(tokens, entities):\n",
        "      if token.startswith(\"##\"):\n",
        "          new_tokens[-1] = new_tokens[-1] + token[2:]\n",
        "      else:\n",
        "          new_labels.append(label_idx)\n",
        "          new_tokens.append(token)\n",
        "  return new_tokens,new_labels"
      ],
      "metadata": {
        "id": "9p4DV1DwXevX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "abstract='Desipramine treatment decreases 3H-nisoxetine binding and norepinephrine transporter mRNA in SK-N-SHSY5Y cells.\tThe antidepressant desipramine has been shown to decrease synaptic membrane concentrations of the norepinephrine re-uptake transporter (NET) in vivo and in vitro, on both an acute and a chronic basis. The possible contribution of decreased NET synthesis to the chronic downregulation of the NETs has not been definitively established. In this study, we treated SK-N-SHSY5Y cells with 100 nM desipramine for 24 or 72 h, and measured 3H-nisoxetine binding (as an estimate of NETs) and NET mRNA by quantitative reverse transcription polymerase chain reaction. Similar to what has been reported previously, membrane 3H-nisoxetine binding was significantly decreased at both 24 and 72 h (approximately 50% at both time points). However, a significant decrease (64 +/- 8% of paired control) of NET mRNA was observed only at the 72-h time point. We conclude that decreased NET synthesis may contribute to the chronic, but not acute, effect of desipramine to downregulate the NET.'\n",
        "l = sent_tokenize(abstract)\n",
        "for sentence in l:\n",
        "  li=re.sub('[^a-zA-Z]',' ',sentence)\n",
        "  li=li.lower()\n",
        "  li=li.split()\n",
        "  li=[word for word in li if not word in stopwords.words('english')]\n",
        "  sentence = ' '.join(li)\n",
        "  ner_tokens,ner_labels = get_predictions(sentence)\n",
        "\n",
        "  for token, label in zip(ner_tokens, ner_labels):\n",
        "      print(\"{}\\t{}\".format(label, token))"
      ],
      "metadata": {
        "id": "9_ydPZw7XeqE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "75a14b30-e000-4006-ddad-cce9af57dd1f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Chemical\tdesipramine\n",
            "Chemical\ttreatment\n",
            "Oth\tdecreases\n",
            "Chemical\th\n",
            "Oth\tnisoxetine\n",
            "Oth\tbinding\n",
            "Chemical\tnorepinephrine\n",
            "Oth\ttransporter\n",
            "Oth\tmrna\n",
            "Oth\tsk\n",
            "Oth\tn\n",
            "Oth\tshsy\n",
            "Oth\tcells\n",
            "Chemical\tantidepressant\n",
            "Chemical\tdesipramine\n",
            "Oth\tshown\n",
            "Oth\tdecrease\n",
            "Oth\tsynaptic\n",
            "Oth\tmembrane\n",
            "Oth\tconcentrations\n",
            "Chemical\tnorepinephrine\n",
            "Oth\tuptake\n",
            "Oth\ttransporter\n",
            "Oth\tnet\n",
            "Oth\tvivo\n",
            "Oth\tvitro\n",
            "Oth\tacute\n",
            "Oth\tchronic\n",
            "Oth\tbasis\n",
            "Oth\tpossible\n",
            "Oth\tcontribution\n",
            "Oth\tdecreased\n",
            "Oth\tnet\n",
            "Oth\tsynthesis\n",
            "Oth\tchronic\n",
            "Oth\tdownregulation\n",
            "Oth\tnets\n",
            "Oth\tdefinitively\n",
            "Oth\testablished\n",
            "Oth\tstudy\n",
            "Oth\ttreated\n",
            "Oth\tsk\n",
            "Oth\tn\n",
            "Oth\tshsy\n",
            "Oth\tcells\n",
            "Oth\tnm\n",
            "Chemical\tdesipramine\n",
            "Oth\th\n",
            "Oth\tmeasured\n",
            "Oth\th\n",
            "Chemical\tnisoxetine\n",
            "Oth\tbinding\n",
            "Oth\testimate\n",
            "Oth\tnets\n",
            "Oth\tnet\n",
            "Oth\tmrna\n",
            "Oth\tquantitative\n",
            "Oth\treverse\n",
            "Oth\ttranscription\n",
            "Oth\tpolymerase\n",
            "Oth\tchain\n",
            "Oth\treaction\n",
            "Oth\tsimilar\n",
            "Oth\treported\n",
            "Oth\tpreviously\n",
            "Oth\tmembrane\n",
            "Chemical\th\n",
            "Oth\tnisoxetine\n",
            "Oth\tbinding\n",
            "Chemical\tsignificantly\n",
            "Oth\tdecreased\n",
            "Oth\th\n",
            "Oth\tapproximately\n",
            "Oth\ttime\n",
            "Oth\tpoints\n",
            "Oth\thowever\n",
            "Oth\tsignificant\n",
            "Oth\tdecrease\n",
            "Oth\tpaired\n",
            "Oth\tcontrol\n",
            "Oth\tnet\n",
            "Oth\tmrna\n",
            "Oth\tobserved\n",
            "Oth\th\n",
            "Oth\ttime\n",
            "Oth\tpoint\n",
            "Oth\tconclude\n",
            "Oth\tdecreased\n",
            "Oth\tnet\n",
            "Oth\tsynthesis\n",
            "Oth\tmay\n",
            "Oth\tcontribute\n",
            "Oth\tchronic\n",
            "Oth\tacute\n",
            "Oth\teffect\n",
            "Chemical\tdesipramine\n",
            "Oth\tdownregulate\n",
            "Oth\tnet\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ZlU9grDwnwBm"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}